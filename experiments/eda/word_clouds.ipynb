{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\author{Austin Gill}\n",
    "\\title{Exploratory Data Analysis -- Word Clouds}\n",
    "\\maketitle\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to examine word frequency in the haiku dataset in a more qualitative and subjective manner.\n",
    "\n",
    "The intent is to build a word cloud not only for all of the words in the corpus, but also for\n",
    "\n",
    "* flowers\n",
    "* colors\n",
    "* animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automagically reimport haikulib if it changes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport haikulib.utils.data\n",
    "%aimport haikulib.utils.nlp\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 9)\n",
    "\n",
    "data_dir = haikulib.utils.data.get_data_dir() / \"experiments\" / \"eda\" / \"word_clouds\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud with Stop Words\n",
    "\n",
    "If we build the word cloud without removing stop words, the results are less illuminating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = haikulib.utils.data.get_bag_of(column=\"haiku\", kind=\"words\")\n",
    "wordcloud = WordCloud(\n",
    "    max_words=500, width=1600, height=900, background_color=\"white\"\n",
    ").generate_from_frequencies(bag)\n",
    "wordcloud.to_file(data_dir / \"all-words.png\")\n",
    "\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud without Stop Words\n",
    "\n",
    "However, once all of the stop words are removed, we begin to see more interesting results.\n",
    "\n",
    "As it was put to me, the results are quite stereotypical, but then stereotypes exist for a reason, and in this particular case they seem to be supported by evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = haikulib.utils.data.get_bag_of(column=\"nostopwords\", kind=\"words\")\n",
    "wordcloud = WordCloud(\n",
    "    max_words=500, width=1600, height=900, background_color=\"white\"\n",
    ").generate_from_frequencies(bag)\n",
    "wordcloud.to_file(data_dir / \"without-stopwords.png\")\n",
    "\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the Haiku Corpus for Specific n-Grams\n",
    "\n",
    "In order to build **perfect** word clouds of flowers, colors, and animals, it's necessary to parse and find occurances of the multi-word tokens in the haiku corpus.\n",
    "\n",
    "However the following brute-force approach is untenably slow\n",
    "\n",
    "```python\n",
    "# Concatenate haiku to form list of lines.\n",
    "df = haikulib.utils.data.get_df()\n",
    "corpus = []\n",
    "\n",
    "for haiku in df[\"haiku\"]:\n",
    "    corpus += [line.strip(\" #\") for line in haiku.split(\"/\")]\n",
    "\n",
    "colors = Counter()\n",
    "flowers = Counter()\n",
    "\n",
    "# Worse than O(n^3) complexity - 1min 10sec runtime\n",
    "for line in corpus:\n",
    "    # str.find() does not respect word boundaries, so it will find \"colors\" and \"flowers\" *inside* words.\n",
    "    colors.update([color for color in color_names if line.find(color) != -1])\n",
    "    flowers.update([flower for flower in flower_names if line.find(flower) != -1])\n",
    "```\n",
    "\n",
    "Unfortunately, finding matching n-grams is a difficult problem, and while a generally efficient solution would be interesting, it's out of scope.\n",
    "Further, manual inspect revealed that the generated word clouds did not differ in meaningful ways.\n",
    "\n",
    "So we proceed with single-token names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_names = haikulib.utils.data.get_colors()\n",
    "flower_names = haikulib.utils.data.get_flowers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "colors = Counter()\n",
    "flowers = Counter()\n",
    "\n",
    "# Linear complexity - 2.3ms runtime\n",
    "for word, count in bag.items():\n",
    "    if word in color_names:\n",
    "        colors[word] = count\n",
    "    if word in flower_names:\n",
    "        flowers[word] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flora Word Cloud\n",
    "\n",
    "There are a large amount of flora mentioned in the haiku, so I thought it would be entertaining to look at a word cloud of flowers and trees mentioned in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    max_words=500, width=1600, height=900, background_color=\"white\"\n",
    ").generate_from_frequencies(flowers)\n",
    "wordcloud.to_file(data_dir / \"flora.png\")\n",
    "\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Word Cloud\n",
    "\n",
    "One of the most interesting and unexpected applications of programming that I have found was a PyCon 2017 conference talk titled [Gothic Colors Using Python to understand color in nineteenth century literature](https://www.youtube.com/watch?v=3dDtACSYVx0).\n",
    "This was the first application of programming to a soft science that I recall having been exposed to, and it's made a lasting impression.\n",
    "\n",
    "Ever since watching the talk, I've wanted to apply scientific techniques to solve non-scientific problems.\n",
    "\n",
    "I still intend on producing a color palette for haiku, but in the mean time, a word cloud of color names will do.\n",
    "The color names and their RGB values have been taken from [https://xkcd.com/color/rgb/](https://xkcd.com/color/rgb/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    max_words=100, width=1600, height=900, background_color=\"white\"\n",
    ").generate_from_frequencies(colors)\n",
    "\n",
    "# Set the colors to the actual RGB color values experimentally determined to be associated with that color name.\n",
    "# See: https://xkcd.com/color/rgb/\n",
    "for i, layout in enumerate(wordcloud.layout_):\n",
    "    (color, a), b, c, d, _ = layout\n",
    "    # Black on a black background doesn't look so hot.\n",
    "    rgb = color_names[color] if color != \"white\" else color_names[\"ice\"]\n",
    "    wordcloud.layout_[i] = ((color, a), b, c, d, rgb)\n",
    "\n",
    "wordcloud.to_file(data_dir / \"colors.png\")\n",
    "\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Word Cloud\n",
    "\n",
    "A host of flora and fauna are mentioned in the haiku dataset, so I want to produce a word cloud for animals mentioned in haiku as well.\n",
    "However, compiling a list of animal names is nontrivial, and I prefer to defer the production of an animal word cloud until the previouslly mentioned parsing problems have been addressed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
