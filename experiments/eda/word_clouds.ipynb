{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\author{Austin Gill}\n",
    "\\title{Exploratory Data Analysis -- Word Clouds}\n",
    "\\maketitle\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to examine word frequency in the haiku dataset in a more qualitative and subjective manner.\n",
    "\n",
    "The intent is to build a word cloud not only for all of the words in the corpus, but also for\n",
    "\n",
    "* flowers\n",
    "* colors\n",
    "* animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automagically reimport haikulib if it changes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport haikulib.utils.data\n",
    "%aimport haikulib.utils.nlp\n",
    "\n",
    "from collections import Counter\n",
    "from IPython.display import Image\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "data_dir = haikulib.utils.data.get_data_dir() / \"experiments\" / \"eda\" / \"word_clouds\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud with Stop Words\n",
    "\n",
    "If we build the word cloud without removing stop words, the results are less illuminating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = haikulib.utils.data.get_bag_of(column=\"haiku\", kind=\"words\")\n",
    "wordcloud = WordCloud(\n",
    "    max_words=500, width=1600, height=900, background_color=\"white\"\n",
    ").generate_from_frequencies(bag)\n",
    "\n",
    "wordcloud.to_file(data_dir / \"all-words.png\")\n",
    "# Render generated image at full resolution in a manner that doesn't cache the images.\n",
    "Image(data_dir / \"all-words.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud without Stop Words\n",
    "\n",
    "However, once all of the stop words are removed, we begin to see more interesting results.\n",
    "\n",
    "As it was put to me, the results are quite stereotypical, but then stereotypes exist for a reason, and in this particular case they seem to be supported by evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = haikulib.utils.data.get_bag_of(column=\"nostopwords\", kind=\"words\")\n",
    "wordcloud = WordCloud(\n",
    "    max_words=500, width=1600, height=900, background_color=\"white\"\n",
    ").generate_from_frequencies(bag)\n",
    "\n",
    "wordcloud.to_file(data_dir / \"without-stopwords.png\")\n",
    "Image(data_dir / \"without-stopwords.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the Haiku Corpus for Specific n-Grams\n",
    "\n",
    "In order to build correct (for some definition of correct) word clouds of flower, color, and animal occurences, it's necessary to parse and find occurances of the multi-word tokens in the haiku corpus.\n",
    "\n",
    "The bag-of-words representation of the dataset is not the appropriate representation for finding ngrams.\n",
    "So we proceed by building a different representation of the haiku corpus, and then count ngrams of sizes 1, 2, and 3 that occur in the sets of color, flora, and fauna names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a list of haiku without the `/` and `#` symbols.\n",
    "df = haikulib.utils.data.get_df()\n",
    "corpus = []\n",
    "\n",
    "for haiku in df[\"haiku\"]:\n",
    "    corpus.append(\" \".join(line.strip(\" #\") for line in haiku.split(\"/\")))\n",
    "\n",
    "color_names = haikulib.utils.data.get_colors()\n",
    "flower_names = haikulib.utils.data.get_flowers()\n",
    "animal_names = haikulib.utils.data.get_animals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "colors = Counter()\n",
    "flowers = Counter()\n",
    "animals = Counter()\n",
    "\n",
    "for haiku in corpus:\n",
    "    # Update the counts for this haiku.\n",
    "    colors.update(\n",
    "        haikulib.utils.count_tokens_from(haiku, color_names, ngrams=[1, 2, 3])\n",
    "    )\n",
    "    flowers.update(\n",
    "        haikulib.utils.count_tokens_from(haiku, flower_names, ngrams=[1, 2, 3])\n",
    "    )\n",
    "    animals.update(\n",
    "        haikulib.utils.count_tokens_from(haiku, animal_names, ngrams=[1, 2, 3])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flora Word Cloud\n",
    "\n",
    "There are a large amount of flora mentioned in the haiku, so I thought it would be entertaining to look at a word cloud of flowers and trees mentioned in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    max_words=500, width=1600, height=900, background_color=\"white\"\n",
    ").generate_from_frequencies(flowers)\n",
    "\n",
    "wordcloud.to_file(data_dir / \"flora.png\")\n",
    "Image(data_dir / \"flora.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Word Cloud\n",
    "\n",
    "One of the most interesting and unexpected applications of programming that I have found was a PyCon 2017 conference talk titled [Gothic Colors Using Python to understand color in nineteenth century literature](https://www.youtube.com/watch?v=3dDtACSYVx0).\n",
    "This was the first application of programming to a soft science that I recall having been exposed to, and it's made a lasting impression.\n",
    "\n",
    "Ever since watching the talk, I've wanted to apply scientific techniques to solve non-scientific problems.\n",
    "\n",
    "I still intend on producing a color palette for haiku, but in the mean time, a word cloud of color names will do.\n",
    "The color names and their RGB values have been taken from [https://xkcd.com/color/rgb/](https://xkcd.com/color/rgb/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    max_words=100, width=1600, height=900, background_color=\"white\"\n",
    ").generate_from_frequencies(colors)\n",
    "\n",
    "# Set the colors to the actual RGB color values experimentally determined to be associated with that color name.\n",
    "# See: https://xkcd.com/color/rgb/\n",
    "for i, layout in enumerate(wordcloud.layout_):\n",
    "    (color, a), b, c, d, _ = layout\n",
    "    # Black on a black background doesn't look so hot.\n",
    "    rgb = color_names[color] if color != \"white\" else color_names[\"ice\"]\n",
    "    wordcloud.layout_[i] = ((color, a), b, c, d, rgb)\n",
    "\n",
    "wordcloud.to_file(data_dir / \"colors.png\")\n",
    "Image(data_dir / \"colors.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fauna Word Cloud\n",
    "\n",
    "A host of flora and fauna are mentioned in the haiku dataset, so I want to produce a word cloud for animals mentioned in haiku as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    max_words=500, width=1600, height=900, background_color=\"white\"\n",
    ").generate_from_frequencies(animals)\n",
    "\n",
    "wordcloud.to_file(data_dir / \"fauna.png\")\n",
    "Image(data_dir / \"fauna.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
