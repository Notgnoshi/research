{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\author{Austin Gill}\n",
    "\\title{Exploratory Data Analysis -- Color}\n",
    "\\maketitle\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to build a color palette of my haiku dataset in the same vein as a PyCon 2017 conference talk titled [Gothic Colors: Using Python to understand color in nineteenth century literature](https://www.youtube.com/watch?v=3dDtACSYVx0).\n",
    "\n",
    "This conference talk was the first application of programming to a soft science that I recall being exposed to, and it's made a lasting impression.\n",
    "Ever since watching the talk, I've wanted to apply scientific techniques to solve non-scientific, soft, and natural problems.\n",
    "\n",
    "Here, I intend to parse the use of color from the haiku in an intelligent manner -- one that is aware that the word \"rose\" has different meanings in the sentences\n",
    "\n",
    "* \"I picked a rose.\"\n",
    "* \"Her shoes were rose colored.\"\n",
    "* \"He rose to greet me.\"\n",
    "\n",
    "In a sense, however, the first two uses both contribute to the sense of a \"color palette\" for haiku, so we care only about excluding the third case.\n",
    "\n",
    "In order to do perform this differentiation, the haiku corpus must be part-of-speech tagged.\n",
    "That is, each word must be annotated with its part of speech.\n",
    "This is a daunting task for such a large corpus -- as of the time of this notebook, the corpus contains over 178,000 words!\n",
    "\n",
    "Fortunately POS-tagging is not a new problem, and there exist out-of-the-box methods for performing POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automagically reimport haikulib if it changes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport haikulib.eda\n",
    "%aimport haikulib.utils\n",
    "%aimport haikulib.data\n",
    "%aimport haikulib.nlp\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "data_dir = haikulib.data.get_data_dir() / \"experiments\" / \"eda\" / \"colors\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "pd.set_option(\"display.latex.repr\", True)\n",
    "pd.set_option(\"display.latex.longtable\", True)\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 9)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Naive Approach\n",
    "\n",
    "It's often useful to implement a simpler version of a feature before implementing the full functionality.\n",
    "So before performing POS-tagging and more intelligent color identification, we simply look for any occurance of a color name in the haiku corpus.\n",
    "\n",
    "We do so by stripping the `/` and `#` meta-tokens from each haiku, then look for any $n$ -grams from the corpus that match our list of color names.\n",
    "We use $n \\in \\{1, 2, 3\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form list of haiku without '/' and '#' symbols\n",
    "df = haikulib.data.get_df()\n",
    "corpus = []\n",
    "\n",
    "for haiku in df[\"haiku\"]:\n",
    "    corpus.append(\" \".join(line.strip(\" #\") for line in haiku.split(\"/\")))\n",
    "\n",
    "color_names = haikulib.data.get_colors_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "naive_colors = collections.Counter()\n",
    "for haiku in corpus:\n",
    "    # Update the color counts for this haiku.\n",
    "    naive_colors.update(\n",
    "        haikulib.nlp.count_tokens_from(haiku, color_names, ngrams=[1, 2, 3])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we build a data frame of the color occurences for ease of use in visualization.\n",
    "Before it was sufficient to use the `collections.Counter()` object directly in generating the word cloud, but now we prefer more a more structured data form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relies on dicts being sorted, added in Python 3.6, guaranteed by Python 3.7\n",
    "naive_color_counts = pd.DataFrame({\"color\": list(naive_colors.keys()), \"count\": list(naive_colors.values()), \"html_color\": [color_names[c] for c in naive_colors]})\n",
    "\n",
    "total_color_count = sum(row[\"count\"] for index, row in naive_color_counts.iterrows())\n",
    "\n",
    "print(f\"There are {total_color_count} occurences of color in the corpus\")\n",
    "print(f\"There are {len(naive_color_counts)} unique colors\")\n",
    "\n",
    "naive_color_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Colors using Part-Of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than implement the color parsing as a part of this notebook, it is performed as a part of the `haikulib.eda` library so that the color parsing can be done *on creation* of the `haiku.csv` cleaned data file.\n",
    "This enables using the results of this analysis in other exploration.\n",
    "\n",
    "However, it's useful to examine the implementation of the color parsing code to demonstrate how it works.\n",
    "In order to do this in a manner that prevents copy-pasting implementations --- which inevitably leads to multiple out-of-sync versions of the same code --- I wrote a small introspective helper function to render the source code of the given function as syntax-highlighted HTML in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikulib.utils.display_source('haikulib.utils', 'display_source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine if a word is a color simply by checking if it is contained in our master list of colors, and by checking if it is an adjective or a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikulib.utils.display_source('haikulib.eda.colors', 'is_color')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this relies on each word in the corpus being tagged with their corresponding part-of-speech.\n",
    "This too is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikulib.utils.display_source('haikulib.nlp', 'pos_tag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the line separators and end-of-haiku symbols are ignored, as they do not have a part of speech.\n",
    "\n",
    "Now we can simply find all of the colors in a given haiku as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified to test colors of all three sizes.\n",
    "haiku = \"dark blue lines / in a light olive green sea salt / dreams #\"\n",
    "colors = [\n",
    "    tagged_word[0]\n",
    "    for tagged_word in haikulib.nlp.pos_tag(haiku)\n",
    "    if haikulib.eda.colors.is_color(tagged_word)\n",
    "]\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about finding the color \"dark blue\"?\n",
    "In order to find multi-word colors, we need to parse and test $n$ -grams from the haiku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikulib.utils.display_source('haikulib.eda.colors', 'find_colors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we only use the `is_color()` method discussed above to determine if single-token words are colors.\n",
    "The requirements for ngrams being a color is relaxed to a simple containment check --- is the ngram in our list of known colors?\n",
    "\n",
    "Further notice that there is soul-crushing logic used to parse the colors `[\"light olive green\", \"sea\"]` from the string `\"light olive green sea\"` instead of the colors `[\"olive\", \"green\", \"sea\", \"olive green\", \"light olive green\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikulib.eda.colors.find_colors(haikulib.nlp.pos_tag(haiku))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can parse colors from the haiku before saving the haiku in the `haiku.csv` data file.\n",
    "This enables spatial exploration of the colors, because they are associated with individual haiku rather than building a simple `collections.Counter` object of colors as above with the naive approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikulib.utils.display_source('haikulib.data.initialization', 'init_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = haikulib.data.get_df()\n",
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also produce a `DataFrame` containing the colors, their counts, and their HTML color codes as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagging_color_counts = haikulib.eda.colors.get_color_counts()\n",
    "\n",
    "total_color_count = sum(\n",
    "    row[\"count\"] for index, row in pos_tagging_color_counts.iterrows()\n",
    ")\n",
    "\n",
    "print(f\"There are {total_color_count} occurences of color in the corpus\")\n",
    "print(f\"There are {len(pos_tagging_color_counts)} unique colors\")\n",
    "\n",
    "pos_tagging_color_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the POS-tagging results with those from the naive approach, summarized again below.\n",
    "Notice that we pruned *twenty-two* unique colors by using POS-tagging, and pruned over *three thousand* occurences of color words that were not tagged as adjectives or nouns, or duplicated by the occurence of an ngram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_color_count = sum(row[\"count\"] for index, row in naive_color_counts.iterrows())\n",
    "\n",
    "print(f\"There are {total_color_count} occurences of color in the corpus\")\n",
    "print(f\"There are {len(naive_color_counts)} unique colors\")\n",
    "\n",
    "naive_color_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Palette Visualization\n",
    "\n",
    "There are a number of palette visualization techniques we could use.\n",
    "We will visualize the haiku color palette using\n",
    "* Word cloud\n",
    "* Histogram\n",
    "* Pie Chart\n",
    "* Ordered Grid\n",
    "* Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud\n",
    "\n",
    "**TODO: Generate transparent background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pie Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chronological Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum\n",
    "\n",
    "**TODO: This may not be very enlightening because it's difficult to describe different shades of color.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Adjacency Graph\n",
    "\n",
    "**TODO: Maybe move to a different notebook?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
