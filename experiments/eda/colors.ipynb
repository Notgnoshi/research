{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\author{Austin Gill}\n",
    "\\title{Exploratory Data Analysis -- Color}\n",
    "\\maketitle\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to build a color palette of my haiku dataset in the same vein as a PyCon 2017 conference talk titled [Gothic Colors: Using Python to understand color in nineteenth century literature](https://www.youtube.com/watch?v=3dDtACSYVx0).\n",
    "\n",
    "This conference talk was the first application of programming to a soft science that I recall being exposed to, and it's made a lasting impression.\n",
    "Ever since watching the talk, I've wanted to apply scientific techniques to solve non-scientific, soft, and natural problems.\n",
    "\n",
    "Here, I intend to parse the use of color from the haiku in an intelligent manner -- one that is aware that the word \"rose\" has different meanings in the sentences\n",
    "\n",
    "* \"I picked a rose.\"\n",
    "* \"Her shoes were rose colored.\"\n",
    "* \"He rose to greet me.\"\n",
    "\n",
    "In a sense, however, the first two uses both contribute to the sense of a \"color palette\" for haiku, so we care only about excluding the third case.\n",
    "\n",
    "In order to do perform this differentiation, the haiku corpus must be part-of-speech tagged.\n",
    "That is, each word must be annotated with its part of speech.\n",
    "This is a daunting task for such a large corpus -- as of the time of this notebook, the corpus contains over 178,000 words!\n",
    "\n",
    "Fortunately POS-tagging is not a new problem, and there exist out-of-the-box methods for performing POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automagically reimport haikulib if it changes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import colorsys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import webcolors\n",
    "from IPython.display import Image\n",
    "\n",
    "import haikulib.eda.colors\n",
    "from haikulib import data, nlp, utils\n",
    "\n",
    "data_dir = data.get_data_dir() / \"experiments\" / \"eda\" / \"colors\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "pd.set_option(\"display.latex.repr\", True)\n",
    "pd.set_option(\"display.latex.longtable\", True)\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 9)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Naive Approach\n",
    "\n",
    "It's often useful to implement a simpler version of a feature before implementing the full functionality.\n",
    "So before performing POS-tagging and more intelligent color identification, we simply look for any occurance of a color name in the haiku corpus.\n",
    "\n",
    "We do so by stripping the `/` and `#` meta-tokens from each haiku, then look for any $n$ -grams from the corpus that match our list of color names.\n",
    "We use $n \\in \\{1, 2, 3\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form list of haiku without '/' and '#' symbols\n",
    "df = data.get_df()\n",
    "corpus = []\n",
    "\n",
    "for haiku in df[\"haiku\"]:\n",
    "    corpus.append(\" \".join(line.strip(\" #\") for line in haiku.split(\"/\")))\n",
    "\n",
    "color_names = {r[\"color\"]: r[\"hex\"] for _, r in haikulib.eda.colors.get_colors().iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "naive_colors = collections.Counter()\n",
    "for haiku in corpus:\n",
    "    # Update the color counts for this haiku.\n",
    "    naive_colors.update(\n",
    "        nlp.count_tokens_from(haiku, color_names, ngrams=[1, 2, 3])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we build a data frame of the color occurences for ease of use in visualization.\n",
    "Before it was sufficient to use the `collections.Counter()` object directly in generating the word cloud, but now we prefer more a more structured data form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_color_counts = pd.DataFrame({\"color\": list(naive_colors.keys()), \"count\": list(naive_colors.values()), \"hex\": [color_names[c] for c in naive_colors]})\n",
    "\n",
    "total_color_count = sum(row[\"count\"] for index, row in naive_color_counts.iterrows())\n",
    "\n",
    "print(f\"There are {total_color_count} occurences of color in the corpus\")\n",
    "print(f\"There are {len(naive_color_counts)} unique colors\")\n",
    "\n",
    "naive_color_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Colors using Part-Of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than implement the color parsing as a part of this notebook, it is performed as a part of the `haikulib.eda` library so that the color parsing can be done *on creation* of the `haiku.csv` cleaned data file.\n",
    "This enables using the results of this analysis in other exploration.\n",
    "\n",
    "However, it's useful to examine the implementation of the color parsing code to demonstrate how it works.\n",
    "In order to do this in a manner that prevents copy-pasting implementations --- which inevitably leads to multiple out-of-sync versions of the same code --- I wrote a small introspective helper function to render the source code of the given function as syntax-highlighted HTML in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_source('haikulib.utils', 'display_source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine if a word is a color simply by checking if it is contained in our master list of colors, and by checking if it is an adjective or a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_source('haikulib.eda.colors', 'is_color')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this relies on each word in the corpus being tagged with their corresponding part-of-speech.\n",
    "This too is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_source('haikulib.nlp', 'pos_tag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the line separators and end-of-haiku symbols are ignored, as they do not have a part of speech.\n",
    "\n",
    "Now we can simply find all of the colors in a given haiku as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified to test colors of all three sizes.\n",
    "haiku = \"dark blue lines / in a light olive green sea salt / dreams #\"\n",
    "haiku_colors = [\n",
    "    tagged_word[0]\n",
    "    for tagged_word in nlp.pos_tag(haiku)\n",
    "    if haikulib.eda.colors.is_color(tagged_word)\n",
    "]\n",
    "print(haiku_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about finding the color \"dark blue\"?\n",
    "In order to find multi-word colors, we need to parse and test $n$ -grams from the haiku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_source('haikulib.eda.colors', 'find_colors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we only use the `is_color()` method discussed above to determine if single-token words are colors.\n",
    "The requirements for ngrams being a color is relaxed to a simple containment check --- is the ngram in our list of known colors?\n",
    "\n",
    "Further notice that there is soul-crushing logic used to parse the colors `[\"light olive green\", \"sea\"]` from the string `\"light olive green sea\"` instead of the colors `[\"olive\", \"green\", \"sea\", \"olive green\", \"light olive green\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikulib.eda.colors.find_colors(nlp.pos_tag(haiku))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can parse colors from the haiku before saving the haiku in the `haiku.csv` data file.\n",
    "This enables spatial exploration of the colors, because they are associated with individual haiku rather than building a simple `collections.Counter` object of colors as above with the naive approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_source('haikulib.data.initialization', 'init_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.get_df()\n",
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also produce a `DataFrame` containing the colors, their counts, and their HTML color codes as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagging_color_counts = haikulib.eda.colors.get_colors()\n",
    "\n",
    "total_color_count = pos_tagging_color_counts[\"count\"].sum()\n",
    "used_color_count = pos_tagging_color_counts[\"count\"].astype(bool).sum(axis=0)\n",
    "\n",
    "print(f\"There are {total_color_count} occurences of color in the corpus\")\n",
    "print(f\"There are {used_color_count} unique colors\")\n",
    "\n",
    "pos_tagging_color_counts[[\"color\", \"count\", \"hex\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the POS-tagging results with those from the naive approach, summarized again below.\n",
    "Notice that we pruned over twenty unique colors by using POS-tagging, and pruned over *three thousand* occurences of color words that were not tagged as adjectives or nouns, or duplicated by the occurence of an ngram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_color_count = naive_color_counts[\"count\"].sum()\n",
    "\n",
    "print(f\"There are {total_color_count} occurences of color in the corpus\")\n",
    "print(f\"There are {len(naive_color_counts)} unique colors\")\n",
    "\n",
    "naive_color_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Palette Visualization\n",
    "\n",
    "There are a number of palette visualization techniques we could use.\n",
    "We will visualize the haiku color palette using\n",
    "* Word cloud\n",
    "* Histogram\n",
    "* Pie Chart\n",
    "* Ordered Grid\n",
    "* Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud\n",
    "\n",
    "One visualization technique to understand the usage of color is to use a word cloud, as discussed in another notebook.\n",
    "An advantage of this technique is that it readily displays not only the colors, but the color names as well.\n",
    "Additionally, it gives a good sense for the frequency of each color.\n",
    "\n",
    "Unfortunately, a word cloud does not give a sense for the overall color palette, since the representation is unstructured and random, putting disparate colors next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(data_dir / \"..\" / \"word_clouds\" / \"colors.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram\n",
    "\n",
    "The color histogram, sorted by frequency, is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = haikulib.eda.colors.get_colors()\n",
    "colors.sort_values(by=[\"hsv\", \"count\"], ascending=False, inplace=True)\n",
    "used_colors = colors.loc[colors[\"count\"] != 0].copy()\n",
    "used_colors.sort_values(by=\"count\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.bar(\n",
    "    range(len(used_colors)),\n",
    "    used_colors[\"count\"],\n",
    "    color=used_colors[\"rgb\"],\n",
    "    width=1,\n",
    "    linewidth=0,\n",
    "    log=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the are other ways we might display the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_colors.sort_values(by=\"hsv\", ascending=False, inplace=True)\n",
    "_ = plt.bar(\n",
    "    range(len(used_colors)),\n",
    "    used_colors[\"count\"],\n",
    "    color=used_colors[\"rgb\"],\n",
    "    width=1,\n",
    "    linewidth=0,\n",
    "    log=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = plt.bar(\n",
    "    range(len(colors)),\n",
    "    height=12 ** 3,\n",
    "    width=1,\n",
    "    linewidth=0,\n",
    "    color=colors[\"rgb\"],\n",
    "    log=True,\n",
    "    alpha=0.8,\n",
    ")\n",
    "foreground = plt.bar(\n",
    "    range(len(colors)),\n",
    "    height=colors[\"count\"],\n",
    "    width=3,\n",
    "    linewidth=0,\n",
    "    color=\"black\",\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pie Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chronological Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Adjacency Graph\n",
    "\n",
    "**TODO: Maybe move to a different notebook?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
