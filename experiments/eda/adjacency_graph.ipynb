{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Adjacency Graph\n",
    "\n",
    "What words are adjacent to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport haikulib.utils.data\n",
    "%aimport haikulib.utils.nlp\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\", disable=[\"parser\", \"ner\"])\n",
    "# If the parser and NER are disabled, it's safe to increase the length limit\n",
    "nlp.max_length = 2_000_000\n",
    "\n",
    "sns.set()\n",
    "\n",
    "DATA_DIR = haikulib.utils.data.get_data_dir() / \"experiments\" / \"generation\" / \"adjacency_graph\"\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_graph(corpus):\n",
    "    corpus = corpus.split(\"#\")\n",
    "    edges = collections.Counter()\n",
    "    \n",
    "    for haiku in corpus:\n",
    "        haiku = haiku.split()\n",
    "        haiku = (w for w in haiku if w != \"'s\" and w != \"'\" and w != \"/\")\n",
    "        edges.update(pairwise(haiku))\n",
    "\n",
    "    graph = nx.DiGraph()\n",
    "    for edge, weight in edges.items():\n",
    "        graph.add_edge(*edge, weight=weight)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = haikulib.utils.data.get_df()\n",
    "\n",
    "doc = nlp(\" \".join(df[\"nostopwords\"])[:500])\n",
    "lemmatized_corpus = \" \".join(token.lemma_ for token in doc)\n",
    "graph = adjacency_graph(lemmatized_corpus)\n",
    "\n",
    "nx.write_gexf(graph, str(DATA_DIR / \"partial-adjacencies.gexf\"))\n",
    "nx.draw(graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\" \".join(df[\"nostopwords\"]))\n",
    "lemmatized_corpus = \" \".join(token.lemma_ for token in doc)\n",
    "graph = adjacency_graph(lemmatized_corpus)\n",
    "\n",
    "nx.write_gexf(graph, str(DATA_DIR / \"full-adjacencies.gexf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
