{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Haiku with a Naive LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport haikulib.utils.data\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLanguageModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type,\n",
    "        ntokens,\n",
    "        nembeddings,\n",
    "        nhidden,\n",
    "        nlayers,\n",
    "        dropout=0.5,\n",
    "        tie_weights=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Embedding(ntokens, nembeddings)\n",
    "        if rnn_type in {\"LSTM\", \"GRU\"}:\n",
    "            self.rnn = getattr(nn, rnn_type)(\n",
    "                nembeddings, nhidden, nlayers, dropout=dropout\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"RNN type '{rnn_type}' unknown.\")\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.decoder = nn.Linear(nhidden, ntokens)\n",
    "\n",
    "        # Optionally tie weights as in:\n",
    "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
    "        # https://arxiv.org/abs/1608.05859\n",
    "        # and\n",
    "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\n",
    "        # https://arxiv.org/abs/1611.01462\n",
    "        if tie_weights:\n",
    "            if nhidden != nembeddings:\n",
    "                raise ValueError(\n",
    "                    \"When using the tied flag, number of hidden units must be equal to the number of embeddings\"\n",
    "                )\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhidden = nhidden\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, minibatch, hidden):\n",
    "        embeddings = self.dropout(self.encoder(minibatch))\n",
    "        output, hidden = self.rnn(embeddings, hidden)\n",
    "        output = self.dropout(output)\n",
    "        decoded = self.decoder(\n",
    "            output.view(output.size(0) * output.size(1), output.size(2))\n",
    "        )\n",
    "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
    "\n",
    "    # We need to reset the LSTM states at the beginning of every epoch.\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        if self.rnn_type == \"LSTM\":\n",
    "            return (\n",
    "                weight.new_zeros(self.nlayers, bsz, self.nhidden),\n",
    "                weight.new_zeros(self.nlayers, bsz, self.nhidden),\n",
    "            )\n",
    "        else:\n",
    "            return weight.new_zeros(self.nlayers, bsz, self.nhidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split into training, test, and validation splits.\n",
    "dataset = haikulib.utils.data.HaikuVocabIndexDataset(seq_len=3, method=\"words\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
