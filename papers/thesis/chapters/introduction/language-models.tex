% !TeX root = .//.tex
\section{Modeling Natural Language}\label{sec:introduction:language-models}
\TODO{Describe what a language model is, and its use in the generation of natural language.}

\subsection{Markov Chain Models}
\subsection{Recurrent Neural Networks}\label{sec:language-models:rnns}
\subsection{Linear Short Term Memory Models}\label{sec:language-models:lstms}

\subsection{Word Embeddings}\label{sec:language-models:word-embeddings}
\subsection{word2vec}\label{sec:language-models:word2vec}
\subsection{Global Vectors for Word Representation}\label{sec:language-models:glove}
\subsection{doc2vec}\label{sec:language-models:doc2vec}

\subsection{Encoders and Decoders}\label{sec:language-models:encoders-decoders}
\subsection{seq2seq}\label{sec:language-models:seq2seq}

\subsection{Attention}\label{sec:language-models:attention}
\subsection{Transformers}\label{sec:language-models:transformers}
\subsection{Byte Pair Encodings}\label{sec:language-models:bpe}
\subsection{Bidirectional Encoder Representations from Transformers}\label{sec:language-models:bert}
\subsection{Generative Pre-Training (I)}\label{sec:language-models:gpt}
\subsection{Generative Pre-Training (II)}\label{sec:language-models:gpt-2}
